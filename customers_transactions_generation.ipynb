{"cells":[{"cell_type":"markdown","id":"bb92dcb5-ded5-4ead-800c-5d8345aa4876","metadata":{"nteract":{"transient":{"deleting":false}}},"source":["# Generacion de la base de datos de clientes y de las transacciones"]},{"cell_type":"code","execution_count":7,"id":"1efb96c8-953d-4f93-9616-74ccc974f776","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2024-09-05T16:06:58.5320554Z","execution_start_time":"2024-09-05T16:06:58.3011718Z","livy_statement_state":"available","normalized_state":"finished","parent_msg_id":"feab243d-369a-432e-b04a-8d3998141246","queued_time":"2024-09-05T16:06:57.8480926Z","session_id":"353e6ef4-3d09-4a45-aefb-fb91ec5e8b02","session_start_time":null,"spark_pool":null,"state":"finished","statement_id":14,"statement_ids":[14]},"text/plain":["StatementMeta(, 353e6ef4-3d09-4a45-aefb-fb91ec5e8b02, 14, Finished, Available, Finished)"]},"metadata":{},"output_type":"display_data"}],"source":["# Libraries to import \n","import random\n","import pandas as pd\n","import datetime\n","import time\n","from azure.eventhub import EventHubProducerClient, EventData\n","import json"]},{"cell_type":"code","execution_count":25,"id":"e6da6eb4-e01c-495d-8d2c-cd6304f6f0cc","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2024-09-03T15:51:18.846079Z","execution_start_time":"2024-09-03T15:51:18.6349689Z","livy_statement_state":"available","normalized_state":"finished","parent_msg_id":"2119f15c-10ff-4e97-b138-136697df4422","queued_time":"2024-09-03T15:51:18.2469581Z","session_id":"1b1f9f77-5627-4bf2-b45b-e08f9306d116","session_start_time":null,"spark_pool":null,"state":"finished","statement_id":42,"statement_ids":[42]},"text/plain":["StatementMeta(, 1b1f9f77-5627-4bf2-b45b-e08f9306d116, 42, Finished, Available, Finished)"]},"metadata":{},"output_type":"display_data"}],"source":["# configuracion la conexion al cliente\n","producer = EventHubProducerClient.from_connection_string(conn_str=connection_str, eventhub_name=entity_name)"]},{"cell_type":"code","execution_count":4,"id":"0c12b7ba-27f2-495e-9830-914ed9279b38","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2024-07-30T13:39:22.9483233Z","execution_start_time":"2024-07-30T13:39:22.7277846Z","livy_statement_state":"available","normalized_state":"finished","parent_msg_id":"460ee042-91d4-4f99-9166-a30c55c0cd04","queued_time":"2024-07-30T13:39:22.3949186Z","session_id":"6e36ff66-d28e-4275-8230-727f002245e4","session_start_time":null,"spark_pool":null,"state":"finished","statement_id":6,"statement_ids":[6]},"text/plain":["StatementMeta(, 6e36ff66-d28e-4275-8230-727f002245e4, 6, Finished, Available, Finished)"]},"metadata":{},"output_type":"display_data"}],"source":["class BankPopulation():\n","\n","    PROB_KYC = [0.85, 0.15]\n","    PROB_PEP = [0.03, 0.97]\n","    PROB_REGION = [0.02, 0.05, 0.15, 0.30, 0.48]\n","    PROB_EMPLOYED = [0.94, 0.06]\n","    PROB_RISK_NAIC = [0.05, 0.95]\n","    PROB_NAME_SCREANING_HIT = [0.05, 0.95]\n","    PROB_ADVERSE_MEDIA_SCREANING_HIT = [0.03, 0.97]\n","\n","    def __init__(self, num_customers: int):\n","        self.num_customers = num_customers\n","\n","    def __assign_value(self, values: list, prob: list, n_cust: int) -> list:\n","        return random.choices(values, weights=prob, k=n_cust)\n","\n","\n","    def create_customers(self) -> pd.DataFrame:\n","        \"\"\"\n","        Method to create a random ids customers sample with size defined previously.\n","\n","        params: self\n","        \"\"\"\n","\n","        # customer id will be between 100000 and 999999\n","        possibles_ids =  [\"{:09d}\".format(i) for i in range(1, self.num_customers + 1)]\n","        # create a sample to avoid duplicates\n","        client_id = random.sample(possibles_ids, self.num_customers)\n","        # create a final df with all ids\n","        client_id_df = pd.DataFrame(client_id, columns=[\"customer_id\"])\n","        return client_id_df\n","    \n","\n","    def kyc_identification(self, df: pd.DataFrame) -> pd.DataFrame:\n","        \"\"\"\n","        Method to randomly create a variable is_kyc_identified which indicates if the customer has sent official documents to identify themselves.\n","\n","        params: df: Dataframe with customers ids\n","        returns: df: Dataframe with user id and if identified\n","        \"\"\"\n","        values_kyc = [1,0]\n","        is_kyc_identified = self.__assign_value(values_kyc, self.PROB_KYC, self.num_customers)\n","        \n","        df[\"is_kyc_identified\"] = is_kyc_identified\n","        return df\n","    \n","    def is_customer_pep(self, df: pd.DataFrame) -> pd.DataFrame:\n","        \"\"\"\n","        Method to randomly create a variable is_customer_pep which indicates if the customer is as Politically Exposed Persons.\n","\n","        params: df: Dataframe with customers ids\n","        returns: df: Dataframe with user id and if identified\n","        \"\"\"\n","        values_pep = [1,0]\n","        is_customer_pep = self.__assign_value(values_pep, self.PROB_PEP, self.num_customers)\n","        df[\"is_customer_pep\"] = is_customer_pep\n","        return df\n","    \n","    def customer_region(self, df: pd.DataFrame) -> pd.DataFrame:\n","        \"\"\"\n","        Method to determine the customer region. It can be selected frfom five categories: prohibited, high risk  restricted,\n","        high risk, medium risk, low risk.\n","\n","        params: df: Dataframe with customers ids\n","        returns: df: Dataframe with user id and customer region\n","        \"\"\"\n","        prohibited_countries = [\"IRN\", \"PRK\", \"SYR\"]\n","        high_restricted_risk_country = [\"AFG\", \"BLR\", \"CUB\", \"SSD\", \"VEN\"]\n","        high_risk_country = [\"ARG\", \"AZE\", \"BRB\", \"ECU\"]\n","        medium_risk_countries = [\"BTN\", \"ISR\", \"IMN\", \"KWT\", \"LUX\"]\n","        low_risk_countries = [\"ESP\", \"NOR\", \"USA\", \"PRT\", \"FRA\", \"DEU\"]\n","\n","        all_countries = (\n","            prohibited_countries +\n","            high_restricted_risk_country +\n","            high_risk_country +\n","            medium_risk_countries +\n","            low_risk_countries\n","        )\n","\n","        country_risk_map = {\n","        country: self.PROB_REGION [\n","            0 if country in prohibited_countries else\n","            1 if country in high_restricted_risk_country else\n","            2 if country in high_risk_country else\n","            3 if country in medium_risk_countries else\n","            4\n","        ]\n","        for country in all_countries\n","        }\n","\n","        country_risk = self.__assign_value(list(country_risk_map.keys()), list(country_risk_map.values()), self.num_customers) \n","\n","        df[\"region\"] = country_risk\n","\n","        return df\n","    \n","    def is_employed(self, df: pd.DataFrame) -> pd.DataFrame:\n","        \"\"\"\n","        Method to randomly determine the customer is employed or unemployed. \n","\n","        params: df: Dataframe with customers ids\n","        returns: df: Dataframe with user id and emplyment situation\n","        \"\"\"\n","\n","        values_employed = [1, 0]\n","\n","        is_employed = self.__assign_value(values_employed, self.PROB_EMPLOYED, self.num_customers)\n","\n","        df[\"is_employed\"] = is_employed\n","\n","        return df\n","    \n","    def industry_naic_code(self, df: pd.DataFrame) -> pd.DataFrame:\n","        \"\"\"\n","        Method to randomly determine the customerÂ´s naics code. \n","\n","        params: df: Dataframe with customers ids\n","        returns: df: Dataframe with user id and naic code\n","        \"\"\"\n","        high_risk_naics = {\n","            \"441110\": \"New car dealers\",\n","            \"441210\": \"Recreational Vehicle Dealers\",\n","            \"522390\": \"Other Activities Related to Credit Intermediation\",\n","            \"713210\": \"Casinos (except Casino Hotels) \",\n","        }\n","        low_risk_naics = {\n","            \"111140\": \"Wheat Farming\",\n","            \"111920\": \"Cotton Farming\",\n","            \"541120\": \"Offices of Notaries\",\n","            \"541410\": \"Interior Design Services\",\n","            \"922160\": \"Fire Protection\",\n","        }\n","\n","        all_naics = (\n","            list(high_risk_naics.keys()) +\n","            list(low_risk_naics.keys())\n","        )\n","\n","        naic_risk_map = {\n","        naic: self.PROB_RISK_NAIC [\n","                0 if naic in high_risk_naics.keys() else\n","                1\n","            ] \n","        for naic in all_naics\n","        }\n","\n","        naic_risk = self.__assign_value(list(naic_risk_map.keys()), list(naic_risk_map.values()), self.num_customers)\n","\n","        df[\"naic_code\"] = naic_risk\n","\n","        return df\n","\n","    def name_screaning_hit(self, df: pd.DataFrame) -> pd.DataFrame:\n","        \"\"\"\n","        \"\"\"\n","        values_ns =  [1,0]\n","\n","        ns_hit  = self.__assign_value(values_ns, self.PROB_NAME_SCREANING_HIT, self.num_customers)\n","\n","        df[\"name_screaning_hit\"] = ns_hit\n","\n","        return df\n","    \n","    def adverse_media_screaning_hit(self, df: pd.DataFrame) -> pd.DataFrame:\n","        \"\"\"\n","        \"\"\"\n","        values_ams =  [1,0]\n","\n","        ams_hit  = self.__assign_value(values_ams, self.PROB_NAME_SCREANING_HIT, self.num_customers)\n","\n","        df[\"adverse_media_screaning_hit\"] = ams_hit\n","\n","        return df\n","    \n","    def date_of_birth_minor(self, df: pd.DataFrame) -> pd.DataFrame:\n","        \"\"\"\n","        \"\"\"\n","\n","        # actual date and date from which the 3 groups of age  will be computed  (14 and 88 years)\n","        fecha_actual = datetime.datetime.now()\n","        fecha_limite_superior = fecha_actual - datetime.timedelta(days=14*365)\n","        fecha_limite_inferior = fecha_actual - datetime.timedelta(days=88*365)\n","\n","        date_of_birth = []\n","        is_minor = []\n","\n","        # Prob of being in the first group of age is 15%\n","        lim_joven = 0.15\n","        # Prob of being in the third group of age is 15%\n","        lim_mayor = 0.85\n","\n","        for _ in range(2000000):\n","            num_random = random.random()\n","\n","            if num_random < lim_joven:\n","                fecha = fecha_limite_superior + datetime.timedelta(days=random.randint(0, 4*365))\n","            elif num_random > lim_mayor:\n","                fecha = fecha_limite_inferior + datetime.timedelta(days=random.randint(1, 12*365))\n","            else:\n","                fecha = fecha_limite_superior - datetime.timedelta(days=random.randint(0, (fecha_limite_superior - fecha_limite_inferior).days))\n","\n","            complete_years = (fecha_actual - fecha).days // 365.25\n","            minor = int(complete_years < 18)\n","\n","            fecha_string = fecha.strftime(\"%d/%m/%Y\")\n","            date_of_birth.append(fecha_string)\n","            is_minor.append(minor)\n","\n","        df[\"date_of_birth\"] = date_of_birth\n","        df[\"is_minor\"] = is_minor\n","\n","        return df"]},{"cell_type":"code","execution_count":27,"id":"a050b1ed-81b5-43de-b8ec-3081c2772ca2","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2024-09-03T15:51:33.845919Z","execution_start_time":"2024-09-03T15:51:33.5506305Z","livy_statement_state":"available","normalized_state":"finished","parent_msg_id":"bca3efb5-4cde-4ed1-a077-497517abf8b3","queued_time":"2024-09-03T15:51:33.2427609Z","session_id":"1b1f9f77-5627-4bf2-b45b-e08f9306d116","session_start_time":null,"spark_pool":null,"state":"finished","statement_id":44,"statement_ids":[44]},"text/plain":["StatementMeta(, 1b1f9f77-5627-4bf2-b45b-e08f9306d116, 44, Finished, Available, Finished)"]},"metadata":{},"output_type":"display_data"}],"source":["# Generador de transacciones\n","from random import choices, lognormvariate, choice\n","from itertools import chain\n","import time\n","import pandas as pd\n","\n","\n","class TransactionGeneration():\n","\n","    def __init__(self, max_transacciones: int, chunk_size: int):\n","        self.max_transacciones = max_transacciones\n","        self.chunk_size = chunk_size\n","    \n","    # rescatamos los clientes para asigbar cada transacciÃ³n.\n","    def fetch_customers(self, df):\n","        \"\"\"\n","        \"\"\"\n","\n","        data_list = [row.customer_id for row in df.select(\"customer_id\").collect()]    \n","\n","        return data_list\n","\n","    def produce_transaction(self, customers: list[str]):\n","        \"\"\" \n","        transaction_id,\n","        user_id,\n","        cantidad,\n","        Hora,\n","        Origen,\n","        Destino,\n","        tipo de transaccion (retirada cash, ingreso cash, envio transfer, recibo transfer, cheque)\n","        Entrante o Saliente\n","        dia y fecha #TODO\n","        \"\"\"\n","        # Countries for transactionality\n","        prohibited_countries = [\"IRN\", \"PRK\", \"SYR\"]\n","        high_restricted_risk_country = [\"AFG\", \"BLR\", \"CUB\", \"SSD\", \"VEN\"]\n","        high_risk_country = [\"ARG\", \"AZE\", \"BRB\", \"ECU\"]\n","        medium_risk_countries = [\"BTN\", \"ISR\", \"IMN\", \"KWT\", \"LUX\"]\n","        low_risk_countries = [\"NOR\", \"USA\", \"PRT\", \"FRA\", \"DEU\"]\n","        home = [\"ESP\"]\n","        prob_region = [0.01, 0.01, 0.01, 0.03, 0.05, 0.89]\n","        prob_transfer = [0.50, 0.05, 0.225, 0.225]\n","\n","        # Countries and associated risk\n","        all_countries = (\n","                prohibited_countries +\n","                high_restricted_risk_country +\n","                high_risk_country +\n","                medium_risk_countries +\n","                low_risk_countries +\n","                home\n","                )   \n","        \n","        country_risk_map = {\n","            country: prob_region [\n","                0 if country in prohibited_countries else\n","                1 if country in high_restricted_risk_country else\n","                2 if country in high_risk_country else\n","                3 if country in medium_risk_countries else\n","                4 if country in low_risk_countries else \n","                5\n","            ]\n","            for country in all_countries\n","            }\n","\n","        # Transaction type.\n","        transaction_type = [\"cash withdraw\",\"cash top up\", \"transfer sent\", \"transfer recieved\"]\n","\n","        # Dataframe creation to store transactions\n","        columns = [\n","            \"transaction_id\",\n","            \"date\",\n","            \"customer_id\", \n","            \"quantity\", \n","            \"transfer_type\",\n","            \"country_of_origin\",\n","            \"country_of_destiny\",\n","            \"inbound_outbound\",\n","        ]\n","        transactions_df = pd.DataFrame(columns=columns)\n","\n","        n = 0 # row number\n","        n_count = 0\n","        n_persist = 30\n","        total_transacciones = 0\n","\n","        try:\n","            transaction_id = spark.sql(\"SELECT MAX(transaction_id) FROM transactions_raw\").collect()[0][0]\n","        except:\n","            transaction_id = 0\n","\n","        try:\n","            while True:\n","                n += 1 \n","                n_count += 1\n","                customer_id = choice(customers)\n","                quantity = round(lognormvariate(mu=5, sigma=3), 2)\n","                transfer_type = choices(transaction_type, prob_transfer, k=1)[0]\n","                country_of_origin = choices(list(country_risk_map.keys()), list(country_risk_map.values()), k=1)[0]\n","                country_of_destiny = choices(list(country_risk_map.keys()), list(country_risk_map.values()), k=1)[0]\n","                date = pd.Timestamp.now()\n","                transaction_id += 1\n","                \n","                if transfer_type in [\"cash withdraw\",\"cash top up\"]:\n","                    country_of_destiny = country_of_origin\n","                \n","                inbound_outbound = \"outbound\" if transfer_type in  [\"cash withdraw\", \"transfer sent\"] else \"inbound\"\n","\n","                \n","\n","                # Enviamos datos al event stream\n","                if (country_of_origin in [\"IRN\", \"PRK\", \"SYR\"]) or (country_of_destiny in [\"IRN\", \"PRK\", \"SYR\"]):\n","                    transaction = {\"transaction_id\": transaction_id, \"date\": str(date),\"customer_id\": customer_id,\"quantity\": quantity,\"transfer_type\": transfer_type,\"country_of_origin\": country_of_origin,\"country_of_destiny\": country_of_destiny, \"inbound_outbound\": inbound_outbound}\n","                    transaction_json = json.dumps(transaction)\n","                    event_data_batch = producer.create_batch()\n","                    event_data_batch.add(EventData(body=transaction_json))\n","                    producer.send_batch(event_data_batch)\n","\n","\n","                transactions_df.loc[n] = [transaction_id, date, customer_id, quantity, transfer_type, country_of_origin, country_of_destiny, inbound_outbound]\n","                \n","                if n_count == self.chunk_size:\n","                    n_count = 0\n","                    n = 0\n","                    transactions_df_spark = spark.createDataFrame(transactions_df)\n","                    transactions_df_spark.write.format(\"delta\").mode(\"append\").save(\"Files/bronze/transactions\")\n","                    transactions_df_spark.write.format(\"delta\").mode(\"append\").saveAsTable(\"transactions_raw\")\n","                    print(f\"Carga de la transaccion numero {total_transacciones + 1} finalizada\")\n","                \n","                # Stopper criteria para no generar demasiadas transacciones\n","                total_transacciones += 1\n","                if total_transacciones == self.max_transacciones:\n","                    print(\"Transaciones maximas cargadas. Saliendo del programa.\")\n","                    break\n","\n","                # time.sleep(0.5)\n","        except KeyboardInterrupt:\n","            print(\"Generacion de transacciones finalizada\")\n","        finally:\n","            # cerramos el cliente\n","            producer.close()\n","\n"]},{"cell_type":"code","execution_count":6,"id":"26086729-8920-4c1e-a4b2-6a5685e2e3ee","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2024-09-13T16:35:39.3690306Z","execution_start_time":"2024-09-13T16:35:38.6068148Z","livy_statement_state":"available","normalized_state":"finished","parent_msg_id":"8f22239a-6d88-4314-a5ae-857ba602c4d2","queued_time":"2024-09-13T16:35:38.2916283Z","session_id":"b1c192f0-af34-4ae2-b922-72d89e4ba06d","session_start_time":null,"spark_pool":null,"state":"finished","statement_id":10,"statement_ids":[10]},"text/plain":["StatementMeta(, b1c192f0-af34-4ae2-b922-72d89e4ba06d, 10, Finished, Available, Finished)"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["root\n"," |-- transaction_id: long (nullable = true)\n"," |-- date: timestamp (nullable = true)\n"," |-- customer_id: string (nullable = true)\n"," |-- quantity: double (nullable = true)\n"," |-- transfer_type: string (nullable = true)\n"," |-- country_of_origin: string (nullable = true)\n"," |-- country_of_destiny: string (nullable = true)\n"," |-- inbound_outbound: string (nullable = true)\n","\n"]}],"source":["df = spark.sql(\"SELECT * FROM aml_tm.transactions_raw LIMIT 1000\")\n","\n","df.printSchema()"]}],"metadata":{"dependencies":{"lakehouse":{"default_lakehouse":"a7565f6c-536f-46b5-a425-20440465cbf1","default_lakehouse_name":"aml_tm","default_lakehouse_workspace_id":"13c54c9b-b00c-4491-97bb-db55c69dbcba"}},"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"display_name":"Synapse PySpark","language":"Python","name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"es"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default"},"synapse_widget":{"state":{},"version":"0.1"},"widgets":{}},"nbformat":4,"nbformat_minor":5}
